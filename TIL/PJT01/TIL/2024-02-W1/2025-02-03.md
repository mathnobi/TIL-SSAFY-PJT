# TIL - 2025/02/03


## 오늘 한 일
- GPU 서버에서 학습시킨 AI 모델을 Django 기반 API로 통합하여 웹 서비스에 적용
  - ../../src/model01_2.png
- 데이터 품질 향상
  - 존댓말 데이터 반말로 변환

<br>

## 문제가 있었던 것
- 학습 시킨 AI 모델에서 어떤 부분을 django에 옮겨야 하는지 고민 됐다.
- 대화 데이터 300개가 너무 적다.
  - 적어도 10만개는 있어야 한다는 얘기를 들었다.
  - gpt에게 물어본 결과 적어도 1만개는 있어야 한다고 했다.
  - 실제 학습 시킨 모델 결과도 썩 마음에 들지 않아 큰일이다.
    - ../../src/model01_1.png

<br>

## 새로 배운 것
### 팀 프로젝트
- 30분 쉬는 시간 포기하고 대화 데이터의 품질을 향상 시켰다.
  - 쉬지 않아도 죽지 않는다!
  - 효율 별로 안떨어지고 잘 했다.

### 개인 공부
- 학습시킨 모델의 파일에서 `models/models/chatbot_model` 안에 있는 파일들을 Django  바깥에 `trained_models/chatbot_model` 안에 넣는다.
  - 다른 data나 코드들은 필요 없다.
- 모델 학습 코드에서 살린 코드
  - 모델 및 토크나이저 로딩 코드
  - prompt 생성 및 추론 코드
  - API 엔드포인트 코드
- 모델 학습 코드에서 필요 없는 코드
  - 데이터 로딩 및 전처리 코드
  - 학습용 데이터 준비 및 토큰화 코드
  - Dataset 및 DataLoader 생성 코드
  - 훈련 설정 및 실행 코드
  - 대화 인터페이스 코드 (DjangoAPI가 없기 때문에 로컬에서 실행하기 위해 필요했던 코드)

-빅데이터를 다룰 때 코딩이 무조건 필요하다는 것을 느꼈다.
  - 대화 데이터 300개였는데도 냅다 텍스트 파일 들어가니까 눈이 혼란스러웠다.
  - 일일히 보는 게 아니라 존댓말 특징을 잡아 코딩을 돌리는게 낫다는 것을 알았다.

<br>

## 아직 잘 모르는 것, 부족한 것
- 데이터 크롤링을 하는 방법을 잘 모른다.
- 데이터가 얼마나 필요한지 실제로 경험해봐야 제대로 안다.
  - 눈으로 다 확인해봐야 적성이 풀린다.
  - 이게 내 단점인 것 같다.
  - 꼼꼼하게 해야 한다는 뜻으로 장점일지도...^^

<br>

## 잘 한 것
- 안쉬고 열심히 했다.

- 집 가서도 알고리즘 스터디를 하고 운동을 갔다. 뿌듯하다.